#!/bin/bash
# jbenninghoff 2013-Mar-8 vi: set ai et sw=3 tabstop=3:

### TeraGen (specify size using 100 Byte records)
size=$[1*1000*1000*1000]  #100GB for quick runs when tuning
size=$[100*1000*1000]  #10GB for quick runs when tuning
size=$[10*1000*1000*1000] #1TB for full TeraSort run
chunksize=$[1*256*1024*1024] # default size
chunksize=$[3*256*1024*1024] # Fat map tasks
maps=$[($size*100)/$chunksize] #Map count for TeraGen resulting in no sharded/chunked files
maps=$(echo $maps | awk '{printf "%.0f\n", $1*1.05}') #Bash doesnt do floating point
hadooppath=$(ls -d /opt/mapr/hadoop/hadoop-* -c1 | sort -n | tail -1 | xargs echo) #find latest hadoop installed

#TBD Check for existing teragen data and skip teragen if OK.  Ask user.
if (hadoop fs -stat /benchmarks/tera/in); then
   echo Using existing TeraGen data
   echo "Use: hadoop fs -rm -r /benchmarks/tera/in, to remove and trigger new TeraGen"
   sleep 3
else
   hadoop fs -rm -r /benchmarks/tera/in #Delete previous data generated by teragen
   maprcli volume create -name benchmarks -path /benchmarks -replication 1
   hadoop fs -chmod 777 /benchmarks
   hadoop fs -mkdir /benchmarks/tera
   hadoop mfs -setchunksize $chunksize /benchmarks/tera  #Set MFS chunksize to 768MB for fat map tasks
   [ $? -ne 0 ] && { echo "setchunksize failed, set chunksize on /benchmarks/tera to $chunksize manually"; exit; }
   # Run TeraGen
   hadoop jar $hadooppath/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.*.jar teragen \
   -Dmapreduce.job.maps=$maps \
   -Dmapreduce.map.disk=0 \
   -Dmapreduce.map.cpu.vcores=0 \
   -Dmapreduce.map.speculative=false \
   $size /benchmarks/tera/in
   sleep 3
fi

hadoop mfs -ls /benchmarks/tera/in | grep ^-rwx | tail 

# Define vars for TeraSort run
logname=terasort-$(date -Imin|cut -c-16).log
nodes=$(maprcli node list -columns hostname,cpus,service |grep nodemanager |wc --lines)
((rtasks=nodes*${1:-2})) # Start with 2 reduce tasks per node, reduce tasks per node limited by available RAM
echo nodes=$nodes | tee $logname
echo rtasks=$rtasks | tee -a $logname
hadoop fs -rm -r /benchmarks/tera/out

case $chunksize in
   $[3*256*1024*1024] )
      echo "Running TeraSort (size=$size) using 'fat' map tasks (fewer map tasks, reduces MxR shuffle)"
      sleep 2
      hadoop jar $hadooppath/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.*.jar terasort \
      -Dmapreduce.map.disk=0 \
      -Dmapreduce.map.cpu.vcores=0 \
      -Dmapreduce.map.output.compress=false \
      -Dmapreduce.map.sort.spill.percent=0.99 \
      -Dmapreduce.map.memory.mb=2000 \
      -Dmapreduce.map.java.opts="-Xmx1900m -Xms1900m" \
      -Dmapreduce.task.io.sort.mb=1500 \
      -Dmapreduce.task.io.sort.factor=100 \
#      -Dmapreduce.reduce.disk=0.5 \
#      -Dmapreduce.reduce.cpu.vcores=1 \
      -Dmapreduce.reduce.shuffle.parallelcopies=$nodes \
      -Dmapreduce.reduce.merge.inmem.threshold=0 \
      -Dmapreduce.job.reduces=$rtasks \
      -Dmapreduce.job.reduce.slowstart.completedmaps=0.85 \
      -Dyarn.app.mapreduce.am.log.level=ERROR \
      /benchmarks/tera/in /benchmarks/tera/out 2>&1 | tee terasort.tmp
      ;;
   $[1*256*1024*1024] )
      echo "Running TeraSort (size=$size) using normal map tasks (more map tasks)"
      sleep 2
      hadoop jar $hadooppath/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.*.jar terasort \
      -Dmapreduce.map.disk=0 \
      -Dmapreduce.map.cpu.vcores=0 \
      -Dmapreduce.map.output.compress=false \
      -Dmapreduce.map.sort.spill.percent=0.99 \
#      -Dmapreduce.reduce.disk=1.33 \
#      -Dmapreduce.reduce.cpu.vcores=1 \      
      -Dmapreduce.reduce.shuffle.parallelcopies=$nodes \
      -Dmapreduce.reduce.merge.inmem.threshold=0 \
      -Dmapreduce.task.io.sort.mb=480 \
      -Dmapreduce.task.io.sort.factor=100 \
      -Dmapreduce.job.reduces=$rtasks \
      -Dmapreduce.job.reduce.slowstart.completedmaps=0.55 \
      -Dyarn.app.mapreduce.am.log.level=ERROR \
      /benchmarks/tera/in /benchmarks/tera/out 2>&1 | tee terasort.tmp
      ;;
   *) echo Undefined chunk size!; exit ;;
esac

#-Dmapreduce.map.speculative=false \
#-Dmapreduce.reduce.speculative=false \
#-Dmapreduce.reduce.memory.mb=3000 \
# maprcli config load -keys cldb.balancer.role.paused
# maprcli config load -keys cldb.balancer.disk.paused
# maprcli config save -values '{"cldb.balancer.disk.paused":"1"}'
# maprcli config save -values '{"cldb.balancer.role.paused":"1"}'

# Post-process the TeraSort job output
sleep 3
# Capture the job history log
myj=$(grep 'INFO mapreduce.Job: Running job' terasort.tmp |awk '{print $7}')
myd=$(date +'%Y/%m/%d')
until (hadoop fs -stat /var/mapr/cluster/yarn/rm/staging/history/done/$myd/000000/$myj\*.jhist); do
 echo Waiting for /var/mapr/cluster/yarn/rm/staging/history/done/$myd/000000/$myj\*.jhist; sleep 5
done
myf=$(hadoop fs -ls /var/mapr/cluster/yarn/rm/staging/history/done/$myd/000000/$myj\*.jhist |awk '{print $8}')
#echo "HISTORY FILE: $myf"

mapred job -history $myf >> $logname  # capture the run log
cat $0 >> $logname # append actual script run to the log
head -22 $logname  # show the top of the log with elapsed time, etc
echo View $logname for full job stats
cat terasort.tmp >> $logname; rm terasort.tmp
./mapr-audit.sh >> $logname

# To validate TeraSort output, uncomment below and change output folder
# hadoop jar /opt/mapr/hadoop/hadoop-0.20.2/hadoop-0.20.2-dev-examples.jar teravalidate /benchmarks/tera/out /benchmarks/tera/validate
